{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb54908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5149a2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "customer = cudf.read_csv('./data/customer.csv')\n",
    "lineorder_o = cudf.read_csv('./data/lineorder.csv')\n",
    "date = cudf.read_csv(\"./data/date.csv\")\n",
    "part = cudf.read_csv(\"./data/part.csv\")\n",
    "supplier = cudf.read_csv(\"./data/supplier.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3689c398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e09f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df = {\n",
    "\"customer\": customer,\n",
    "\"part\": part,\n",
    "\"date\": date,\n",
    "\"supplier\": supplier\n",
    "}\n",
    "dim_key = {\n",
    "\"customer\": \"CUSTKEY\",\n",
    "\"part\": \"PARTKEY\",\n",
    "\"date\": \"DATEKEY\",\n",
    "\"supplier\": \"SUPPKEY\"\n",
    "}\n",
    "dim_feature = {\n",
    "\"customer\": [\"NAME\", \"ADDRESS\", \"CITY\"],\n",
    "\"part\":  [\"NAME\", \"MFGR\", \"CATEGORY\", \"BRAND1\"],\n",
    "\"date\":[\"DATE\", \"DAYOFWEEK\", \"MONTH\", \"YEAR\", \"YEARMONTHNUM\", \"YEARMONTH\", \"DAYNUMINWEEK\"],\n",
    "\"supplier\": [\"NAME\", \"ADDRESS\", \"CITY\", \"NATION\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e7cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for relation in dim_key:\n",
    "    key = dim_key[relation]\n",
    "    dim_df[relation].set_index(key,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4a82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lineorder_o.rename(columns={\"ORDERDATE\": \"DATEKEY\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e69c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f20f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    def __init__(self, fact):\n",
    "        self.fact = fact\n",
    "        self.message_storage = dict()\n",
    "        self.splits = dict()\n",
    "    def compute_dummy(self):\n",
    "        ts = self.fact.agg({'REVENUE': 'sum'}).iloc[0]\n",
    "        self.tc = self.fact.agg({'REVENUE': 'count'}).iloc[0]\n",
    "        self.fact['REVENUE'] -= ts/self.tc\n",
    "        self.ts = 0\n",
    "    def assign_total(self,ts, tc):\n",
    "        self.ts = ts\n",
    "        self.tc = tc\n",
    "    def find_best_splits(self):\n",
    "        for relation in dim_key:\n",
    "            key = dim_key[relation]\n",
    "            self.message_storage[relation] = self.fact.groupby(key).agg({'REVENUE': 'sum', key:'count'})\n",
    "            self.message_storage[relation].columns=[\"s\", \"c\"]\n",
    "    \n",
    "        ts, tc = self.ts, self.tc\n",
    "        for relation in dim_feature:\n",
    "            key = dim_key[relation]\n",
    "            absorption = dim_df[relation].merge(self.message_storage[relation], on=key)\n",
    "            for feature in dim_feature[relation]:\n",
    "                agg = absorption[[feature] + [\"s\",\"c\"]].groupby(feature)\\\n",
    "                .agg({'s': 'sum', 'c':'sum'})\\\n",
    "                .sort_index().cumsum()\n",
    "                if len(agg) <= 1:\n",
    "                    continue\n",
    "                agg[\"criteria\"]= agg[\"s\"]*agg[\"s\"]/agg[\"c\"] + (ts - agg[\"s\"]) / (tc - agg[\"c\"]) * (ts - agg[\"s\"])\n",
    "                max_row = agg[:-1].sort_values('criteria', ascending=False).head(1)\n",
    "                max_value = max_row[\"criteria\"].iloc[-1]\n",
    "                max_s = max_row[\"s\"].iloc[-1]\n",
    "                max_c = max_row[\"c\"].iloc[-1]\n",
    "                max_index = max_row.index[-1]\n",
    "                self.splits[max_value] = (relation, feature, max_index, max_s, max_c)\n",
    "                \n",
    "    def split(self):\n",
    "        max_key = max(self.splits.keys())\n",
    "        relation, feature, max_index, max_s, max_c = self.splits[max_key]\n",
    "        df = dim_df[relation]\n",
    "        key = dim_key[relation]\n",
    "        left_ts, left_tc, right_ts, right_tc = 0,0,0,0 \n",
    "        if max_index > 500:\n",
    "            msg = df[[feature]][df[feature] > max_index]\n",
    "            left_ts = self.ts - max_s\n",
    "            left_tc = self.tc - max_c\n",
    "            right_ts = max_s\n",
    "            right_tc = max_c\n",
    "        else:\n",
    "            msg = df[[feature]][df[feature] <= max_index]\n",
    "            left_ts = max_s\n",
    "            left_tc = max_c\n",
    "            right_ts = self.ts - max_s\n",
    "            right_tc = self.tc - max_c\n",
    "        n1 = node(self.fact.merge(msg, on=key, how='leftsemi'))\n",
    "        print(len(n1.fact),left_tc)\n",
    "        n1.assign_total(left_ts, left_tc)\n",
    "        n2 = node(self.fact.merge(msg, on=key, how='leftanti'))\n",
    "        n2.assign_total(right_ts, right_tc)\n",
    "        self.clean()\n",
    "        return n1, n2\n",
    "    \n",
    "    def clean(self):\n",
    "        del self.fact\n",
    "        for relation in self.message_storage:\n",
    "            df = self.message_storage[relation]\n",
    "            del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n0 = node(lineorder_o.sample(frac=0.5))\n",
    "n0.compute_dummy()\n",
    "n0.find_best_splits()\n",
    "n1, n2 = n0.split()\n",
    "n1.find_best_splits()\n",
    "n2.find_best_splits()\n",
    "n3, n4  = n1.split()\n",
    "n5, n6  = n2.split()\n",
    "n3.find_best_splits()\n",
    "n4.find_best_splits()\n",
    "n5.find_best_splits()\n",
    "n6.find_best_splits()\n",
    "l1, l2 = n3.split()\n",
    "l3, l4 = n4.split()\n",
    "l5, l6 = n5.split()\n",
    "l7, l8 = n6.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0332c1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bbb3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c16a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4171cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    def __init__(self, fact):\n",
    "        self.fact = fact\n",
    "        self.message_storage = dict()\n",
    "        self.splits = dict()\n",
    "    def compute_dummy(self):\n",
    "        ts = self.fact.agg({'REVENUE': 'sum'}).iloc[0]\n",
    "        self.tc = self.fact.agg({'REVENUE': 'count'}).iloc[0]\n",
    "        self.fact['REVENUE'] -= ts/self.tc\n",
    "        self.ts = 0\n",
    "    def assign_total(self,ts, tc):\n",
    "        self.ts = ts\n",
    "        self.tc = tc\n",
    "    def find_best_splits(self):\n",
    "        for relation in dim_key:\n",
    "            key = dim_key[relation]\n",
    "            self.message_storage[relation] = self.fact.groupby(key).agg({'REVENUE': 'sum', key:'count'})\n",
    "            self.message_storage[relation].columns=[\"s\", \"c\"]\n",
    "\n",
    "        ts, tc = self.ts, self.tc\n",
    "\n",
    "        absorptions = []\n",
    "\n",
    "        for relation in dim_feature:\n",
    "            key = dim_key[relation]\n",
    "            absorption = dim_df[relation].merge(self.message_storage[relation], on=key)\n",
    "            absorption = absorption.melt(id_vars=['s', 'c'], value_vars=dim_feature[relation], var_name='key', value_name='value')\n",
    "            absorption[\"relation\"] = relation\n",
    "            absorptions.append(absorption)\n",
    "\n",
    "        result = cudf.concat(absorptions)\n",
    "        result = result.groupby([\"relation\", \"key\", \"value\"]).sum().reset_index()\n",
    "        result = result.sort_values([\"relation\", 'key', 'value'])\n",
    "\n",
    "        result[['s', 'c']] = result.groupby([\"relation\",\"key\"])[['s', 'c']].cumsum()\n",
    "\n",
    "        if result['s'].dtype != 'float64':\n",
    "            result['s'] = result['s'].astype('float64')\n",
    "        if result['c'].dtype != 'float64':\n",
    "            result['c'] = result['c'].astype('float64')\n",
    "\n",
    "        result = result[result['c'] < tc]\n",
    "        result[\"ts\"] = float(ts)\n",
    "        result[\"tc\"] = float(tc)\n",
    "        result[\"criteria\"]= result.eval(f\"s*s/c + (ts-s)/(tc -c) * (ts - s)\")\n",
    "        idx = result.groupby(['relation', 'key'])['criteria'].idxmax()\n",
    "        result = result.iloc[idx]\n",
    "\n",
    "        max_row = result.nlargest(1, 'criteria')\n",
    "        max_value = max_row[\"criteria\"].iloc[-1]\n",
    "        max_s = max_row[\"s\"].iloc[-1]\n",
    "        max_c = max_row[\"c\"].iloc[-1]\n",
    "        max_index = max_row[\"value\"].iloc[-1]\n",
    "        relation = max_row[\"relation\"].iloc[-1]\n",
    "        feature = max_row[\"key\"].iloc[-1]\n",
    "        self.splits[max_value] = (relation, feature, max_index, max_s, max_c)\n",
    "                \n",
    "    def split(self):\n",
    "        max_key = max(self.splits.keys())\n",
    "        relation, feature, max_index, max_s, max_c = self.splits[max_key]\n",
    "        df = dim_df[relation]\n",
    "        key = dim_key[relation]\n",
    "        left_ts, left_tc, right_ts, right_tc = 0,0,0,0 \n",
    "        if max_index > 500:\n",
    "            msg = df[[feature]][df[feature] > max_index]\n",
    "            left_ts = self.ts - max_s\n",
    "            left_tc = self.tc - max_c\n",
    "            right_ts = max_s\n",
    "            right_tc = max_c\n",
    "        else:\n",
    "            msg = df[[feature]][df[feature] <= max_index]\n",
    "            left_ts = max_s\n",
    "            left_tc = max_c\n",
    "            right_ts = self.ts - max_s\n",
    "            right_tc = self.tc - max_c\n",
    "        n1 = node(self.fact.merge(msg, on=key, how='leftsemi'))\n",
    "        print(len(n1.fact),left_tc)\n",
    "        n1.assign_total(left_ts, left_tc)\n",
    "        n2 = node(self.fact.merge(msg, on=key, how='leftanti'))\n",
    "        n2.assign_total(right_ts, right_tc)\n",
    "        self.clean()\n",
    "        return n1, n2\n",
    "    \n",
    "    def clean(self):\n",
    "        del self.fact\n",
    "        for relation in self.message_storage:\n",
    "            df = self.message_storage[relation]\n",
    "            del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de826e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n0 = node(lineorder_o)\n",
    "n0.compute_dummy()\n",
    "n0.find_best_splits()\n",
    "n1, n2 = n0.split()\n",
    "n1.find_best_splits()\n",
    "n2.find_best_splits()\n",
    "n3, n4  = n1.split()\n",
    "n5, n6  = n2.split()\n",
    "n3.find_best_splits()\n",
    "n4.find_best_splits()\n",
    "n5.find_best_splits()\n",
    "n6.find_best_splits()\n",
    "l1, l2 = n3.split()\n",
    "l3, l4 = n4.split()\n",
    "l5, l6 = n5.split()\n",
    "l7, l8 = n6.split()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
